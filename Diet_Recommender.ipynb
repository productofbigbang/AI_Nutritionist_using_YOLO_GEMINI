{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7uFa9G_tGdg",
        "outputId": "ba65eccb-ef2c-4983-b6d6-772a0dcee0f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.41.0)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.2.75)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.7.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.112.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.3.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.5)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.8.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.9)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.5.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.30.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (12.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.6 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.6.6)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.19.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.137.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.6->google-generativeai) (1.24.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.63.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.15.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.6.20)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.37.2)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio ultralytics google-generativeai pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import os\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"\"#Enter your api key here\n",
        "# we trained a pretrained yolov8 on similar food classification task on manually curated dataset\n",
        "os.environ[\"YOLO_MODEL_PATH\"] = \"custom_model.pt\" #If you store custom model file in some other folder put the same address here\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sU7HBq-EtRY6"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import requests\n",
        "import io\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import google.generativeai as genai\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "jwFUGWFpwOjm"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drive.mount('/content/drive') chamge this accordingly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYPHJjGUwL1d",
        "outputId": "d2b52efb-943e-43c6-bfd1-0c781dd6a2ae"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=\"\")#put your gemini api key here we used the free version\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\")"
      ],
      "metadata": {
        "id": "vG-3jUZ4wEYN"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import google.generativeai as genai\n",
        "from PIL import Image\n",
        "import gradio as gr\n",
        "import logging\n",
        "import time\n",
        "import re\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Helper function to log and print\n",
        "def log_print(message, level=logging.INFO):\n",
        "    print(message)\n",
        "    logging.log(level, message)\n",
        "\n",
        "# Load YOLO model\n",
        "def load_yolo_model(model_path):\n",
        "    log_print(\"Loading YOLO model\")\n",
        "    return YOLO(model_path)\n",
        "\n",
        "# Perform object detection and return the first detected object\n",
        "def detect_first_object(yolo_model, image_path):\n",
        "    log_print(\"Detecting first object in the image\")\n",
        "    results = yolo_model.predict(source=image_path, imgsz=640, conf=0.05)\n",
        "    if len(results[0].boxes) > 0:\n",
        "        log_print(\"Object detected\")\n",
        "        return results[0].boxes[0]\n",
        "    log_print(\"No objects detected in the image\", level=logging.WARNING)\n",
        "    return None\n",
        "\n",
        "# Crop the first detected object\n",
        "def crop_first_object(image_path, box):\n",
        "    log_print(\"Cropping the first detected object\")\n",
        "    original_image = Image.open(image_path)\n",
        "    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "    cropped_image = original_image.crop((x1, y1, x2, y2))\n",
        "    return cropped_image\n",
        "\n",
        "# Process image and generate nutrition info\n",
        "def process_image(image, height, weight, age, sex, diet, api_key, yolo_model):\n",
        "    log_print(\"Starting image processing\")\n",
        "\n",
        "    # Save the uploaded image\n",
        "    image_path = \"temp_image.jpg\"\n",
        "    image.save(image_path)\n",
        "    log_print(f\"Saved uploaded image to {image_path}\")\n",
        "\n",
        "    # Detect the first object\n",
        "    first_box = detect_first_object(yolo_model, image_path)\n",
        "\n",
        "    if first_box is None:\n",
        "        log_print(\"No food items detected in the image\", level=logging.WARNING)\n",
        "        return \"No food items detected in the image.\", \"\", \"\"\n",
        "\n",
        "    # Crop the first object\n",
        "    cropped_image = crop_first_object(image_path, first_box)\n",
        "    cropped_image_path = \"cropped_image.jpg\"\n",
        "    cropped_image.save(cropped_image_path)\n",
        "    log_print(\"First object cropped\")\n",
        "    sample_file = Image.open(cropped_image_path)\n",
        "    log_print(\"First object uploaded\")\n",
        "    log_print(f\"Saved cropped image to {cropped_image_path}\")\n",
        "\n",
        "    # Generate content for the cropped image\n",
        "    prompt = \"dont give any formatting just give answer in point add linespace and nothing else give your anwer in points Estimate the quantities of all the different food items in the image. Dont add anyother words apart from what is asked Just straight out give output in cleanly formatted version.\"\n",
        "    log_print(\"Initiating API call\")\n",
        "    nutrition_info = model.generate_content([sample_file, prompt])\n",
        "    log_print(\"Generated nutrition information\")\n",
        "\n",
        "    # Generate macronutrient breakdown\n",
        "    log_print(\"Generating macronutrient breakdown...\")\n",
        "    macro_prompt = f\"dont give any formatting just give answer in point add linespace and nothing else  give your anwer in points  Using these details, give me the breakdown of macronutrients in the diet.Consider the person's height: {height}cm, weight: {weight}kg, age: {age}, and sex: {sex} diet type: {diet} Roughly estimate the quantities of food items to do your calculations. Dont add anyother words apart from what is asked Just straight out give output in cleanly formatted version.\"\n",
        "    macro_info = model.generate_content(nutrition_info.text + macro_prompt)\n",
        "    log_print(\"Generated macronutrient breakdown\")\n",
        "\n",
        "    # Generate RDA table\n",
        "    log_print(\"Generating RDA table...\")\n",
        "    rda_prompt = f\"dont give any formatting just give answer in point add linespace and nothing else  give your anwer in points  Now format this in the form of a neat and clean RDA ponts for the given individual. Consider the person's height: {height}cm, weight: {weight}kg, age: {age}, and sex: {sex} diet type: {diet}.Also suggest what his diet is lakcing what should he add suggest food items under the ehading recomendations ,Dont add anyother words apart from what is asked Just straight out give output in cleanly formatted version.\"\n",
        "    rda_table = model.generate_content(macro_info.text + rda_prompt)\n",
        "    log_print(\"Generated RDA table\")\n",
        "\n",
        "    return nutrition_info, macro_info, rda_table\n",
        "\n",
        "def format_text(text):\n",
        "    # Remove any markdown-style headers\n",
        "    text = re.sub(r'^#+\\s*', '', text, flags=re.MULTILINE)\n",
        "\n",
        "    # Replace bullet points with proper Unicode bullets\n",
        "    text = re.sub(r'^\\s*[-*]\\s', '• ', text, flags=re.MULTILINE)\n",
        "\n",
        "    # Add line breaks for readability\n",
        "    text = text.replace('. ', '.\\n')\n",
        "\n",
        "    # Capitalize the first letter of each sentence\n",
        "    text = '. '.join(sentence.capitalize() for sentence in text.split('. '))\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "def format_table(table_text):\n",
        "    lines = table_text.split('\\n')\n",
        "    formatted_lines = []\n",
        "    for line in lines:\n",
        "        if '|' in line:\n",
        "            cells = [cell.strip() for cell in line.split('|') if cell.strip()]\n",
        "            formatted_line = ' | '.join(f\"{cell:<20}\" for cell in cells)\n",
        "            formatted_lines.append(formatted_line)\n",
        "        else:\n",
        "            formatted_lines.append(line)\n",
        "    return '\\n'.join(formatted_lines)\n",
        "\n",
        "# Gradio interface\n",
        "def gradio_interface(image, height, weight, age, sex, diet):\n",
        "    log_print(\"Starting Gradio interface function\")\n",
        "    api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
        "    yolo_model_path = os.environ.get(\"YOLO_MODEL_PATH\")\n",
        "    yolo_model = load_yolo_model(yolo_model_path)\n",
        "\n",
        "    nutrition_info, macro_info, rda_table = process_image(image, height, weight, age, sex, diet, api_key, yolo_model)\n",
        "\n",
        "    # Format the outputs\n",
        "    formatted_nutrition_info = format_text(nutrition_info.text)\n",
        "    formatted_macro_info = format_text(macro_info.text)\n",
        "    formatted_rda_table = format_table(rda_table.text)\n",
        "\n",
        "    log_print(\"Final Results:\")\n",
        "    log_print(\"Nutrition Info:\")\n",
        "    print(formatted_nutrition_info)\n",
        "    log_print(\"Macronutrient Breakdown:\")\n",
        "    print(formatted_macro_info)\n",
        "    log_print(\"RDA Table:\")\n",
        "    print(formatted_rda_table)\n",
        "\n",
        "    return formatted_nutrition_info, formatted_macro_info, formatted_rda_table\n",
        "\n",
        "# Create Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=gradio_interface,\n",
        "    inputs=[\n",
        "        gr.Image(type=\"pil\", label=\"Upload your meal image\"),\n",
        "        gr.Number(label=\"Height (cm)\"),\n",
        "        gr.Number(label=\"Weight (kg)\"),\n",
        "        gr.Number(label=\"Age\"),\n",
        "        gr.Radio([\"Male\", \"Female\"], label=\"Sex\"),\n",
        "        gr.Radio([\"Vegeterian\", \"Non Vegeterian\",\"Vegan\",\"Eggiterian\"], label=\"Diet\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Nutrition Information\"),\n",
        "        gr.Textbox(label=\"Macronutrient Breakdown\"),\n",
        "        gr.Textbox(label=\"Analysis and Suggestions\")\n",
        "    ],\n",
        "    title=\"Diet Analysis\",\n",
        "    description=\"Upload an image of your meal to get nutrition information and RDA analysis.\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "if __name__ == \"__main__\":\n",
        "    log_print(\"Launching Gradio interface\")\n",
        "    iface.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1pTQqHriyasH",
        "outputId": "4916e483-eac9-4b88-86a8-3a3bb56301af"
      },
      "execution_count": 40,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Launching Gradio interface\n",
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://774215322476dd0afe.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://774215322476dd0afe.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Gradio interface function\n",
            "Loading YOLO model\n",
            "Starting image processing\n",
            "Saved uploaded image to temp_image.jpg\n",
            "Detecting first object in the image\n",
            "\n",
            "image 1/1 /content/temp_image.jpg: 384x640 1 Plate, 128.9ms\n",
            "Speed: 5.6ms preprocess, 128.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Object detected\n",
            "Cropping the first detected object\n",
            "First object cropped\n",
            "First object uploaded\n",
            "Saved cropped image to cropped_image.jpg\n",
            "Initiating API call\n",
            "Generated nutrition information\n",
            "Generating macronutrient breakdown...\n",
            "Generated macronutrient breakdown\n",
            "Generating RDA table...\n",
            "Generated RDA table\n",
            "Final Results:\n",
            "Nutrition Info:\n",
            "• 250 ml dal makhani\n",
            "• 200 ml paneer butter masala\n",
            "• 150 ml malai kofta\n",
            "• 100 ml mix veg\n",
            "• 150 ml dal\n",
            "• 200 gm rice\n",
            "• 2 pieces of samosa\n",
            "• 150 gm salad\n",
            "• 200 gm potato\n",
            "• 250 gm naan\n",
            "• 50 gm onion\n",
            "• 50 gm chutney\n",
            "Macronutrient Breakdown:\n",
            "• calories: 2400-2600 kcal\n",
            "• protein: 80-90 grams\n",
            "• carbohydrates: 350-400 grams\n",
            "• fat: 70-80 grams\n",
            "RDA Table:\n",
            "- Calories: 2400-2600 kcal\n",
            "- Protein: 80-90 grams\n",
            "- Carbohydrates: 350-400 grams\n",
            "- Fat: 70-80 grams\n",
            "\n",
            "Lacking: \n",
            "- Fiber \n",
            "\n",
            "Recommendations:\n",
            "- Oats\n",
            "- Lentils\n",
            "- Broccoli \n",
            "- Apples\n",
            "- Almonds \n",
            "\n",
            "Starting Gradio interface function\n",
            "Loading YOLO model\n",
            "Starting image processing\n",
            "Saved uploaded image to temp_image.jpg\n",
            "Detecting first object in the image\n",
            "\n",
            "image 1/1 /content/temp_image.jpg: 640x640 4 Plates, 225.8ms\n",
            "Speed: 4.7ms preprocess, 225.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Object detected\n",
            "Cropping the first detected object\n",
            "First object cropped\n",
            "First object uploaded\n",
            "Saved cropped image to cropped_image.jpg\n",
            "Initiating API call\n",
            "Generated nutrition information\n",
            "Generating macronutrient breakdown...\n",
            "Generated macronutrient breakdown\n",
            "Generating RDA table...\n",
            "Generated RDA table\n",
            "Final Results:\n",
            "Nutrition Info:\n",
            "• 2 rotis\n",
            "• 1 small bowl of dal \n",
            "• 1 cup of rice\n",
            "• 1 cup of mixed vegetable curry\n",
            "• 1 cup of potato and peas curry \n",
            "• 6 slices of cucumber\n",
            "Macronutrient Breakdown:\n",
            "• carbohydrates: 250-300 grams\n",
            "• protein: 40-50 grams\n",
            "• fat: 30-40 grams\n",
            "RDA Table:\n",
            "- Carbohydrates: Too high\n",
            "- Protein: Too low\n",
            "- Fat: Too low \n",
            "\n",
            "Recommendations:\n",
            "\n",
            "- Increase protein intake (140-175 grams)\n",
            "- Increase fat intake (56-70 grams)\n",
            "- Chicken\n",
            "- Fish\n",
            "- Eggs\n",
            "- Nuts\n",
            "- Seeds\n",
            "- Avocado\n",
            "- Olive oil\n",
            "- Salmon \n",
            "\n",
            "Starting Gradio interface function\n",
            "Loading YOLO model\n",
            "Starting image processing\n",
            "Saved uploaded image to temp_image.jpg\n",
            "Detecting first object in the image\n",
            "\n",
            "image 1/1 /content/temp_image.jpg: 640x384 1 Plate, 129.3ms\n",
            "Speed: 3.1ms preprocess, 129.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Object detected\n",
            "Cropping the first detected object\n",
            "First object cropped\n",
            "First object uploaded\n",
            "Saved cropped image to cropped_image.jpg\n",
            "Initiating API call\n",
            "Generated nutrition information\n",
            "Generating macronutrient breakdown...\n",
            "Generated macronutrient breakdown\n",
            "Generating RDA table...\n",
            "Generated RDA table\n",
            "Final Results:\n",
            "Nutrition Info:\n",
            "• 3 parathas\n",
            "• 1/2 cup dal \n",
            "• 1/2 cup raita \n",
            "• 1/2 cup chutney\n",
            "• 1/2 cup chai\n",
            "Macronutrient Breakdown:\n",
            "• carbohydrates: ~90-100 grams \n",
            "• protein: ~20-25 grams\n",
            "• fat: ~25-30 grams\n",
            "RDA Table:\n",
            "- Carbohydrates: 300-350 grams\n",
            "- Protein: 105-140 grams\n",
            "- Fat: 50-70 grams\n",
            "\n",
            "Lacking:\n",
            "Protein\n",
            "Fat\n",
            "\n",
            "Recommendations:\n",
            "Tofu\n",
            "Tempeh\n",
            "Lentils\n",
            "Beans\n",
            "Nuts\n",
            "Seeds\n",
            "Avocados\n",
            "Olive oil\n",
            "Coconut oil \n",
            "Greek Yogurt \n",
            "Quinoa\n",
            "Starting Gradio interface function\n",
            "Loading YOLO model\n",
            "Starting image processing\n",
            "Saved uploaded image to temp_image.jpg\n",
            "Detecting first object in the image\n",
            "\n",
            "image 1/1 /content/temp_image.jpg: 640x384 1 Plate, 126.3ms\n",
            "Speed: 2.9ms preprocess, 126.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Object detected\n",
            "Cropping the first detected object\n",
            "First object cropped\n",
            "First object uploaded\n",
            "Saved cropped image to cropped_image.jpg\n",
            "Initiating API call\n",
            "Generated nutrition information\n",
            "Generating macronutrient breakdown...\n",
            "Generated macronutrient breakdown\n",
            "Generating RDA table...\n",
            "Generated RDA table\n",
            "Final Results:\n",
            "Nutrition Info:\n",
            "• paratha: 3\n",
            "• dal: 150 grams\n",
            "• raita: 150 grams \n",
            "• chutney: 50 grams \n",
            "• chai: 1 cup (around 150 ml)\n",
            "Macronutrient Breakdown:\n",
            "• calories: 800-850 kcal\n",
            "• protein: 25-30 grams\n",
            "• carbohydrates: 120-130 grams\n",
            "• fat: 25-30 grams\n",
            "RDA Table:\n",
            "- Calories: Moderately low\n",
            "- Protein: Too low\n",
            "- Carbohydrates: Adequate\n",
            "- Fat: Adequate\n",
            "\n",
            "Recommendations:\n",
            "\n",
            "- Increase protein intake to at least 50-70 grams per day.\n",
            "- Include protein-rich vegetarian foods like lentils, beans, tofu, tempeh, edamame, quinoa, Greek yogurt (if consuming dairy), nuts, and seeds. \n",
            "\n",
            "Starting Gradio interface function\n",
            "Loading YOLO model\n",
            "Starting image processing\n",
            "Saved uploaded image to temp_image.jpg\n",
            "Detecting first object in the image\n",
            "\n",
            "image 1/1 /content/temp_image.jpg: 640x384 1 Plate, 131.8ms\n",
            "Speed: 4.8ms preprocess, 131.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Object detected\n",
            "Cropping the first detected object\n",
            "First object cropped\n",
            "First object uploaded\n",
            "Saved cropped image to cropped_image.jpg\n",
            "Initiating API call\n",
            "Generated nutrition information\n",
            "Generating macronutrient breakdown...\n",
            "Generated macronutrient breakdown\n",
            "Generating RDA table...\n",
            "Generated RDA table\n",
            "Final Results:\n",
            "Nutrition Info:\n",
            "• aloo paratha: 3\n",
            "• dal makhani: 1 serving\n",
            "• raita: 1 serving \n",
            "• green chutney: 1 serving \n",
            "• chai: 1 serving\n",
            "Macronutrient Breakdown:\n",
            "• calories: 1200-1500kcal\n",
            "• protein: 30-40g\n",
            "• carbohydrates: 200-250g\n",
            "• fat: 40-50g\n",
            "RDA Table:\n",
            "- Calories: 1200-1500kcal\n",
            "- Protein: 30-40g\n",
            "- Carbohydrates: 200-250g\n",
            "- Fat: 40-50g\n",
            "\n",
            "Lacking:\n",
            "Height, weight, age, sex, and diet type information is needed to assess dietary adequacy.\n",
            "\n",
            "Recommendations:\n",
            "Provide the missing information (height, weight, age, sex, diet type) for personalized recommendations. \n",
            "\n",
            "Starting Gradio interface function\n",
            "Loading YOLO model\n",
            "Starting image processing\n",
            "Saved uploaded image to temp_image.jpg\n",
            "Detecting first object in the image\n",
            "\n",
            "image 1/1 /content/temp_image.jpg: 640x640 4 Plates, 340.7ms\n",
            "Speed: 13.2ms preprocess, 340.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Object detected\n",
            "Cropping the first detected object\n",
            "First object cropped\n",
            "First object uploaded\n",
            "Saved cropped image to cropped_image.jpg\n",
            "Initiating API call\n",
            "Generated nutrition information\n",
            "Generating macronutrient breakdown...\n",
            "Generated macronutrient breakdown\n",
            "Generating RDA table...\n",
            "Generated RDA table\n",
            "Final Results:\n",
            "Nutrition Info:\n",
            "• roti: 3\n",
            "• dal: 150 ml\n",
            "• rice: 200 g\n",
            "• curry: 200 g\n",
            "• salad: 100 g\n",
            "Macronutrient Breakdown:\n",
            "• calories: 800-900 kcal\n",
            "• protein: 30-35 g\n",
            "• carbohydrates: 150-160 g\n",
            "• fat: 15-20 g\n",
            "RDA Table:\n",
            "- Calories: Slightly low for a 25-year-old male with a height of 170cm and weight of 70kg. Aim for 2200-2500kcal for healthy weight maintenance.\n",
            "- Protein: Significantly low. Aim for at least 70-85g of protein per day to support muscle mass and overall health. \n",
            "- Carbohydrates: Within a healthy range.\n",
            "- Fat: On the lower end. Aim for 40-60g of healthy fats per day for hormone production and overall well-being.\n",
            "\n",
            "Diet is lacking:\n",
            "- Calories\n",
            "- Protein\n",
            "- Fat\n",
            "\n",
            "Recommendations:\n",
            "- Tofu\n",
            "- Tempeh\n",
            "- Legumes\n",
            "- Nuts\n",
            "- Seeds\n",
            "- Avocado\n",
            "- Olive oil\n",
            "- Quinoa\n",
            "- Brown rice\n",
            "- Protein powder (pea protein, soy protein, brown rice protein)\n",
            "Starting Gradio interface function\n",
            "Loading YOLO model\n",
            "Starting image processing\n",
            "Saved uploaded image to temp_image.jpg\n",
            "Detecting first object in the image\n",
            "\n",
            "image 1/1 /content/temp_image.jpg: 384x640 1 Plate, 131.5ms\n",
            "Speed: 4.2ms preprocess, 131.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Object detected\n",
            "Cropping the first detected object\n",
            "First object cropped\n",
            "First object uploaded\n",
            "Saved cropped image to cropped_image.jpg\n",
            "Initiating API call\n",
            "Generated nutrition information\n",
            "Generating macronutrient breakdown...\n",
            "Generated macronutrient breakdown\n",
            "Generating RDA table...\n",
            "Generated RDA table\n",
            "Final Results:\n",
            "Nutrition Info:\n",
            "• 4 chapatis\n",
            "• 6 samosas \n",
            "• 1 cup dal makhani \n",
            "• 1 cup saag paneer \n",
            "• 1 cup butter chicken \n",
            "• 1 cup yellow rice \n",
            "• 1 cup aloo curry \n",
            "• 1 cup chicken curry\n",
            "• 1/2 cup raita \n",
            "• 1/2 cup green chutney \n",
            "• 1/4 cup onion salad\n",
            "• 1 cup salad\n",
            "Macronutrient Breakdown:\n",
            "• calories: 2200-2500 kcal\n",
            "• protein: 80-100g \n",
            "• carbohydrates: 300-350g \n",
            "• fat: 60-80g\n",
            "RDA Table:\n",
            "- Calories: 2200-2500 kcal\n",
            "- Protein: 80-100g (Slightly low for building muscle mass)\n",
            "- Carbohydrates: 300-350g \n",
            "- Fat: 60-80g \n",
            "\n",
            "Lacking: Protein \n",
            "\n",
            "Recommendations:\n",
            "- Tofu\n",
            "- Tempeh\n",
            "- Lentils\n",
            "- Chickpeas\n",
            "- Quinoa\n",
            "- Spirulina\n",
            "- Hemp seeds\n",
            "- Chia seeds\n",
            "- Nutritional yeast \n",
            "\n",
            "Starting Gradio interface function\n",
            "Loading YOLO model\n",
            "Starting image processing\n",
            "Saved uploaded image to temp_image.jpg\n",
            "Detecting first object in the image\n",
            "\n",
            "image 1/1 /content/temp_image.jpg: 640x384 1 Plate, 127.3ms\n",
            "Speed: 3.2ms preprocess, 127.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Object detected\n",
            "Cropping the first detected object\n",
            "First object cropped\n",
            "First object uploaded\n",
            "Saved cropped image to cropped_image.jpg\n",
            "Initiating API call\n",
            "Generated nutrition information\n",
            "Generating macronutrient breakdown...\n",
            "Generated macronutrient breakdown\n",
            "Generating RDA table...\n",
            "Generated RDA table\n",
            "Final Results:\n",
            "Nutrition Info:\n",
            "• 3 parathas \n",
            "• 1/2 cup daal \n",
            "• 1/2 cup raita \n",
            "• 1/2 cup chutney \n",
            "• 1/2 cup chai\n",
            "Macronutrient Breakdown:\n",
            "• carbohydrates: 150-180 grams\n",
            "• protein: 25-30 grams\n",
            "• fat: 30-35 grams\n",
            "RDA Table:\n",
            "- Carbohydrates: Slightly high, aim for 130-150 grams for weight management. \n",
            "- Protein:  Adequate. \n",
            "- Fat:  Adequate. \n",
            "\n",
            "Lacking: \n",
            "- Fiber \n",
            "\n",
            "Recommendations: \n",
            "- Oats\n",
            "- Fruits \n",
            "- Vegetables\n",
            "- Legumes \n",
            "\n",
            "Starting Gradio interface function\n",
            "Loading YOLO model\n",
            "Starting image processing\n",
            "Saved uploaded image to temp_image.jpg\n",
            "Detecting first object in the image\n",
            "\n",
            "image 1/1 /content/temp_image.jpg: 640x384 1 Plate, 214.7ms\n",
            "Speed: 3.2ms preprocess, 214.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
            "Object detected\n",
            "Cropping the first detected object\n",
            "First object cropped\n",
            "First object uploaded\n",
            "Saved cropped image to cropped_image.jpg\n",
            "Initiating API call\n",
            "Generated nutrition information\n",
            "Generating macronutrient breakdown...\n",
            "Generated macronutrient breakdown\n",
            "Generating RDA table...\n",
            "Generated RDA table\n",
            "Final Results:\n",
            "Nutrition Info:\n",
            "• aloo paratha - 3 \n",
            "• daal - 200 ml\n",
            "• raita - 200 ml \n",
            "• chutney - 100 ml \n",
            "• tea - 100 ml\n",
            "Macronutrient Breakdown:\n",
            "• carbohydrates: 250-300 grams\n",
            "• protein: 30-40 grams\n",
            "• fat: 40-50 grams\n",
            "RDA Table:\n",
            "- Carbohydrates:  Too High\n",
            "- Protein: Too Low\n",
            "- Fat: Too Low\n",
            "\n",
            "Lacking: Protein, Healthy Fats \n",
            "\n",
            "Recommendations: \n",
            "Lean meats \n",
            "Fish\n",
            "Nuts\n",
            "Seeds\n",
            "Avocados\n",
            "Olive Oil \n",
            "Eggs \n",
            "Beans \n",
            "Lentils \n",
            "Greek Yogurt \n",
            "Tofu\n",
            "Tempeh \n",
            "Protein shakes\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://774215322476dd0afe.gradio.live\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TGe6KDSWudVa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}